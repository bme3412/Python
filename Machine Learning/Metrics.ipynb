{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f54c0d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "98352ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=e08b6903-9fc3-4a3c-aafb-9107c5364351 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('e08b6903-9fc3-4a3c-aafb-9107c5364351').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "\n",
       "[3 rows x 31 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('creditcard.csv')[:80_000]\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7b278059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Shape of X = (80000, 28) y = (80000,), #Fraud Cases = 196'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns=['Time', 'Amount', 'Class']).values\n",
    "y = df['Class'].values\n",
    "f\"Shape of X = {X.shape} y = {y.shape}, #Fraud Cases = {y.sum()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5533b9f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "mod = LogisticRegression(class_weight={0:1, 1:2}, max_iter=1000)\n",
    "mod.fit(X,y).predict(X).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0f14452b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "??lr.score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6fd9eadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brendan/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "/Users/brendan/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the train scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(max_iter=1000), n_jobs=-1,\n",
       "             param_grid={'class_weight': [{0: 1, 1: 1.0},\n",
       "                                          {0: 1, 1: 1.6551724137931034},\n",
       "                                          {0: 1, 1: 2.310344827586207},\n",
       "                                          {0: 1, 1: 2.9655172413793105},\n",
       "                                          {0: 1, 1: 3.6206896551724137},\n",
       "                                          {0: 1, 1: 4.275862068965517},\n",
       "                                          {0: 1, 1: 4.931034482758621},\n",
       "                                          {0: 1, 1: 5.586206896551724},\n",
       "                                          {0: 1, 1: 6.241379310344827},\n",
       "                                          {0: 1, 1: 6.896551724137931},...\n",
       "                                          {0: 1, 1: 15.413793103448276},\n",
       "                                          {0: 1, 1: 16.06896551724138},\n",
       "                                          {0: 1, 1: 16.724137931034484},\n",
       "                                          {0: 1, 1: 17.379310344827587},\n",
       "                                          {0: 1, 1: 18.03448275862069},\n",
       "                                          {0: 1, 1: 18.689655172413794},\n",
       "                                          {0: 1, 1: 19.344827586206897},\n",
       "                                          {0: 1, 1: 20.0}]},\n",
       "             refit='precision', return_train_score=True,\n",
       "             scoring={'min_both': make_scorer(min_recall_precision),\n",
       "                      'precision': make_scorer(precision_score),\n",
       "                      'recall': make_scorer(recall_score)})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, recall_score, make_scorer\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator = LogisticRegression(max_iter=1000),\n",
    "    param_grid={'class_weight': [{0:1, 1: v} for v in np.linspace(1,20,30)]},\n",
    "    scoring={'precision': make_scorer(precision_score), 'recall': make_scorer(recall_score),\n",
    "            'min_both': make_scorer(min_recall_precision)},\n",
    "    refit='precision',\n",
    "    return_train_score=True,\n",
    "    cv = 10,\n",
    "    n_jobs=-1)\n",
    "grid.fit(X,y, sample_weight=np.log(1+df['Amount']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1a726284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_recall_precision(est, y_true, y_pred):\n",
    "    y_pred = est.predict(X)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    return min(recall, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e4f609e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8181818181818182, 0.5969387755102041)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision_score(y, grid.predict(X)), recall_score(y, grid.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5507d03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=8042cd80-ca5e-4be9-a659-e1820daa7733 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('8042cd80-ca5e-4be9-a659-e1820daa7733').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_precision</th>\n",
       "      <th>split1_test_precision</th>\n",
       "      <th>split2_test_precision</th>\n",
       "      <th>split3_test_precision</th>\n",
       "      <th>...</th>\n",
       "      <th>split2_train_min_both</th>\n",
       "      <th>split3_train_min_both</th>\n",
       "      <th>split4_train_min_both</th>\n",
       "      <th>split5_train_min_both</th>\n",
       "      <th>split6_train_min_both</th>\n",
       "      <th>split7_train_min_both</th>\n",
       "      <th>split8_train_min_both</th>\n",
       "      <th>split9_train_min_both</th>\n",
       "      <th>mean_train_min_both</th>\n",
       "      <th>std_train_min_both</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.302426</td>\n",
       "      <td>0.502885</td>\n",
       "      <td>0.010095</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>{0: 1, 1: 1.0}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 1.0}}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.188494</td>\n",
       "      <td>0.147411</td>\n",
       "      <td>0.006954</td>\n",
       "      <td>0.003580</td>\n",
       "      <td>{0: 1, 1: 1.6551724137931034}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 1.6551724137931034}}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.194294</td>\n",
       "      <td>0.191823</td>\n",
       "      <td>0.012360</td>\n",
       "      <td>0.007996</td>\n",
       "      <td>{0: 1, 1: 2.310344827586207}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 2.310344827586207}}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.081728</td>\n",
       "      <td>0.140043</td>\n",
       "      <td>0.008388</td>\n",
       "      <td>0.005658</td>\n",
       "      <td>{0: 1, 1: 2.9655172413793105}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 2.9655172413793105}}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.097977</td>\n",
       "      <td>0.190276</td>\n",
       "      <td>0.007271</td>\n",
       "      <td>0.003555</td>\n",
       "      <td>{0: 1, 1: 3.6206896551724137}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 3.6206896551724137}}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.010120</td>\n",
       "      <td>0.118044</td>\n",
       "      <td>0.007619</td>\n",
       "      <td>0.004907</td>\n",
       "      <td>{0: 1, 1: 4.275862068965517}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 4.275862068965517}}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.070241</td>\n",
       "      <td>0.149726</td>\n",
       "      <td>0.008425</td>\n",
       "      <td>0.005360</td>\n",
       "      <td>{0: 1, 1: 4.931034482758621}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 4.931034482758621}}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.066735</td>\n",
       "      <td>0.189249</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>0.008936</td>\n",
       "      <td>{0: 1, 1: 5.586206896551724}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 5.586206896551724}}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.080601</td>\n",
       "      <td>0.187657</td>\n",
       "      <td>0.007334</td>\n",
       "      <td>0.004098</td>\n",
       "      <td>{0: 1, 1: 6.241379310344827}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 6.241379310344827}}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.961459</td>\n",
       "      <td>0.169749</td>\n",
       "      <td>0.005298</td>\n",
       "      <td>0.003014</td>\n",
       "      <td>{0: 1, 1: 6.896551724137931}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 6.896551724137931}}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.025671</td>\n",
       "      <td>0.206076</td>\n",
       "      <td>0.007611</td>\n",
       "      <td>0.003438</td>\n",
       "      <td>{0: 1, 1: 7.551724137931034}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 7.551724137931034}}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.055983</td>\n",
       "      <td>0.209039</td>\n",
       "      <td>0.007251</td>\n",
       "      <td>0.003631</td>\n",
       "      <td>{0: 1, 1: 8.206896551724139}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 8.206896551724139}}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.144960</td>\n",
       "      <td>0.227154</td>\n",
       "      <td>0.008105</td>\n",
       "      <td>0.005081</td>\n",
       "      <td>{0: 1, 1: 8.862068965517242}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 8.862068965517242}}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.175877</td>\n",
       "      <td>0.226687</td>\n",
       "      <td>0.005577</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>{0: 1, 1: 9.517241379310345}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 9.517241379310345}}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.239339</td>\n",
       "      <td>0.223305</td>\n",
       "      <td>0.007986</td>\n",
       "      <td>0.004711</td>\n",
       "      <td>{0: 1, 1: 10.172413793103448}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 10.172413793103448}}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.219368</td>\n",
       "      <td>0.155182</td>\n",
       "      <td>0.005573</td>\n",
       "      <td>0.002097</td>\n",
       "      <td>{0: 1, 1: 10.827586206896552}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 10.827586206896552}}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.200353</td>\n",
       "      <td>0.214487</td>\n",
       "      <td>0.005988</td>\n",
       "      <td>0.002668</td>\n",
       "      <td>{0: 1, 1: 11.482758620689655}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 11.482758620689655}}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.207141</td>\n",
       "      <td>0.132929</td>\n",
       "      <td>0.008856</td>\n",
       "      <td>0.007199</td>\n",
       "      <td>{0: 1, 1: 12.137931034482758}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 12.137931034482758}}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.300420</td>\n",
       "      <td>0.172569</td>\n",
       "      <td>0.006593</td>\n",
       "      <td>0.003348</td>\n",
       "      <td>{0: 1, 1: 12.793103448275861}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 12.793103448275861}}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.178359</td>\n",
       "      <td>0.162296</td>\n",
       "      <td>0.006106</td>\n",
       "      <td>0.003408</td>\n",
       "      <td>{0: 1, 1: 13.448275862068964}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 13.448275862068964}}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.186277</td>\n",
       "      <td>0.239808</td>\n",
       "      <td>0.004176</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>{0: 1, 1: 14.103448275862068}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 14.103448275862068}}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1.104359</td>\n",
       "      <td>0.117628</td>\n",
       "      <td>0.007796</td>\n",
       "      <td>0.002652</td>\n",
       "      <td>{0: 1, 1: 14.758620689655173}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 14.758620689655173}}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.168025</td>\n",
       "      <td>0.180231</td>\n",
       "      <td>0.006314</td>\n",
       "      <td>0.001958</td>\n",
       "      <td>{0: 1, 1: 15.413793103448276}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 15.413793103448276}}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.215390</td>\n",
       "      <td>0.168112</td>\n",
       "      <td>0.007902</td>\n",
       "      <td>0.003529</td>\n",
       "      <td>{0: 1, 1: 16.06896551724138}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 16.06896551724138}}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.257637</td>\n",
       "      <td>0.230354</td>\n",
       "      <td>0.008262</td>\n",
       "      <td>0.004273</td>\n",
       "      <td>{0: 1, 1: 16.724137931034484}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 16.724137931034484}}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.251575</td>\n",
       "      <td>0.232875</td>\n",
       "      <td>0.009911</td>\n",
       "      <td>0.003331</td>\n",
       "      <td>{0: 1, 1: 17.379310344827587}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 17.379310344827587}}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.163544</td>\n",
       "      <td>0.243494</td>\n",
       "      <td>0.011635</td>\n",
       "      <td>0.012337</td>\n",
       "      <td>{0: 1, 1: 18.03448275862069}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 18.03448275862069}}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.189824</td>\n",
       "      <td>0.227363</td>\n",
       "      <td>0.011638</td>\n",
       "      <td>0.014710</td>\n",
       "      <td>{0: 1, 1: 18.689655172413794}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 18.689655172413794}}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.185967</td>\n",
       "      <td>0.250485</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>{0: 1, 1: 19.344827586206897}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 19.344827586206897}}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.974265</td>\n",
       "      <td>0.191937</td>\n",
       "      <td>0.005974</td>\n",
       "      <td>0.003752</td>\n",
       "      <td>{0: 1, 1: 20.0}</td>\n",
       "      <td>{'class_weight': {0: 1, 1: 20.0}}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        2.302426      0.502885         0.010095        0.005208   \n",
       "1        1.188494      0.147411         0.006954        0.003580   \n",
       "2        1.194294      0.191823         0.012360        0.007996   \n",
       "3        1.081728      0.140043         0.008388        0.005658   \n",
       "4        1.097977      0.190276         0.007271        0.003555   \n",
       "5        1.010120      0.118044         0.007619        0.004907   \n",
       "6        1.070241      0.149726         0.008425        0.005360   \n",
       "7        1.066735      0.189249         0.007576        0.008936   \n",
       "8        1.080601      0.187657         0.007334        0.004098   \n",
       "9        0.961459      0.169749         0.005298        0.003014   \n",
       "10       1.025671      0.206076         0.007611        0.003438   \n",
       "11       1.055983      0.209039         0.007251        0.003631   \n",
       "12       1.144960      0.227154         0.008105        0.005081   \n",
       "13       1.175877      0.226687         0.005577        0.003162   \n",
       "14       1.239339      0.223305         0.007986        0.004711   \n",
       "15       1.219368      0.155182         0.005573        0.002097   \n",
       "16       1.200353      0.214487         0.005988        0.002668   \n",
       "17       1.207141      0.132929         0.008856        0.007199   \n",
       "18       1.300420      0.172569         0.006593        0.003348   \n",
       "19       1.178359      0.162296         0.006106        0.003408   \n",
       "20       1.186277      0.239808         0.004176        0.000749   \n",
       "21       1.104359      0.117628         0.007796        0.002652   \n",
       "22       1.168025      0.180231         0.006314        0.001958   \n",
       "23       1.215390      0.168112         0.007902        0.003529   \n",
       "24       1.257637      0.230354         0.008262        0.004273   \n",
       "25       1.251575      0.232875         0.009911        0.003331   \n",
       "26       1.163544      0.243494         0.011635        0.012337   \n",
       "27       1.189824      0.227363         0.011638        0.014710   \n",
       "28       1.185967      0.250485         0.006373        0.002747   \n",
       "29       0.974265      0.191937         0.005974        0.003752   \n",
       "\n",
       "               param_class_weight  \\\n",
       "0                  {0: 1, 1: 1.0}   \n",
       "1   {0: 1, 1: 1.6551724137931034}   \n",
       "2    {0: 1, 1: 2.310344827586207}   \n",
       "3   {0: 1, 1: 2.9655172413793105}   \n",
       "4   {0: 1, 1: 3.6206896551724137}   \n",
       "5    {0: 1, 1: 4.275862068965517}   \n",
       "6    {0: 1, 1: 4.931034482758621}   \n",
       "7    {0: 1, 1: 5.586206896551724}   \n",
       "8    {0: 1, 1: 6.241379310344827}   \n",
       "9    {0: 1, 1: 6.896551724137931}   \n",
       "10   {0: 1, 1: 7.551724137931034}   \n",
       "11   {0: 1, 1: 8.206896551724139}   \n",
       "12   {0: 1, 1: 8.862068965517242}   \n",
       "13   {0: 1, 1: 9.517241379310345}   \n",
       "14  {0: 1, 1: 10.172413793103448}   \n",
       "15  {0: 1, 1: 10.827586206896552}   \n",
       "16  {0: 1, 1: 11.482758620689655}   \n",
       "17  {0: 1, 1: 12.137931034482758}   \n",
       "18  {0: 1, 1: 12.793103448275861}   \n",
       "19  {0: 1, 1: 13.448275862068964}   \n",
       "20  {0: 1, 1: 14.103448275862068}   \n",
       "21  {0: 1, 1: 14.758620689655173}   \n",
       "22  {0: 1, 1: 15.413793103448276}   \n",
       "23   {0: 1, 1: 16.06896551724138}   \n",
       "24  {0: 1, 1: 16.724137931034484}   \n",
       "25  {0: 1, 1: 17.379310344827587}   \n",
       "26   {0: 1, 1: 18.03448275862069}   \n",
       "27  {0: 1, 1: 18.689655172413794}   \n",
       "28  {0: 1, 1: 19.344827586206897}   \n",
       "29                {0: 1, 1: 20.0}   \n",
       "\n",
       "                                             params  split0_test_precision  \\\n",
       "0                  {'class_weight': {0: 1, 1: 1.0}}                    NaN   \n",
       "1   {'class_weight': {0: 1, 1: 1.6551724137931034}}                    NaN   \n",
       "2    {'class_weight': {0: 1, 1: 2.310344827586207}}                    NaN   \n",
       "3   {'class_weight': {0: 1, 1: 2.9655172413793105}}                    NaN   \n",
       "4   {'class_weight': {0: 1, 1: 3.6206896551724137}}                    NaN   \n",
       "5    {'class_weight': {0: 1, 1: 4.275862068965517}}                    NaN   \n",
       "6    {'class_weight': {0: 1, 1: 4.931034482758621}}                    NaN   \n",
       "7    {'class_weight': {0: 1, 1: 5.586206896551724}}                    NaN   \n",
       "8    {'class_weight': {0: 1, 1: 6.241379310344827}}                    NaN   \n",
       "9    {'class_weight': {0: 1, 1: 6.896551724137931}}                    NaN   \n",
       "10   {'class_weight': {0: 1, 1: 7.551724137931034}}                    NaN   \n",
       "11   {'class_weight': {0: 1, 1: 8.206896551724139}}                    NaN   \n",
       "12   {'class_weight': {0: 1, 1: 8.862068965517242}}                    NaN   \n",
       "13   {'class_weight': {0: 1, 1: 9.517241379310345}}                    NaN   \n",
       "14  {'class_weight': {0: 1, 1: 10.172413793103448}}                    NaN   \n",
       "15  {'class_weight': {0: 1, 1: 10.827586206896552}}                    NaN   \n",
       "16  {'class_weight': {0: 1, 1: 11.482758620689655}}                    NaN   \n",
       "17  {'class_weight': {0: 1, 1: 12.137931034482758}}                    NaN   \n",
       "18  {'class_weight': {0: 1, 1: 12.793103448275861}}                    NaN   \n",
       "19  {'class_weight': {0: 1, 1: 13.448275862068964}}                    NaN   \n",
       "20  {'class_weight': {0: 1, 1: 14.103448275862068}}                    NaN   \n",
       "21  {'class_weight': {0: 1, 1: 14.758620689655173}}                    NaN   \n",
       "22  {'class_weight': {0: 1, 1: 15.413793103448276}}                    NaN   \n",
       "23   {'class_weight': {0: 1, 1: 16.06896551724138}}                    NaN   \n",
       "24  {'class_weight': {0: 1, 1: 16.724137931034484}}                    NaN   \n",
       "25  {'class_weight': {0: 1, 1: 17.379310344827587}}                    NaN   \n",
       "26   {'class_weight': {0: 1, 1: 18.03448275862069}}                    NaN   \n",
       "27  {'class_weight': {0: 1, 1: 18.689655172413794}}                    NaN   \n",
       "28  {'class_weight': {0: 1, 1: 19.344827586206897}}                    NaN   \n",
       "29                {'class_weight': {0: 1, 1: 20.0}}                    NaN   \n",
       "\n",
       "    split1_test_precision  split2_test_precision  split3_test_precision  ...  \\\n",
       "0                     NaN                    NaN                    NaN  ...   \n",
       "1                     NaN                    NaN                    NaN  ...   \n",
       "2                     NaN                    NaN                    NaN  ...   \n",
       "3                     NaN                    NaN                    NaN  ...   \n",
       "4                     NaN                    NaN                    NaN  ...   \n",
       "5                     NaN                    NaN                    NaN  ...   \n",
       "6                     NaN                    NaN                    NaN  ...   \n",
       "7                     NaN                    NaN                    NaN  ...   \n",
       "8                     NaN                    NaN                    NaN  ...   \n",
       "9                     NaN                    NaN                    NaN  ...   \n",
       "10                    NaN                    NaN                    NaN  ...   \n",
       "11                    NaN                    NaN                    NaN  ...   \n",
       "12                    NaN                    NaN                    NaN  ...   \n",
       "13                    NaN                    NaN                    NaN  ...   \n",
       "14                    NaN                    NaN                    NaN  ...   \n",
       "15                    NaN                    NaN                    NaN  ...   \n",
       "16                    NaN                    NaN                    NaN  ...   \n",
       "17                    NaN                    NaN                    NaN  ...   \n",
       "18                    NaN                    NaN                    NaN  ...   \n",
       "19                    NaN                    NaN                    NaN  ...   \n",
       "20                    NaN                    NaN                    NaN  ...   \n",
       "21                    NaN                    NaN                    NaN  ...   \n",
       "22                    NaN                    NaN                    NaN  ...   \n",
       "23                    NaN                    NaN                    NaN  ...   \n",
       "24                    NaN                    NaN                    NaN  ...   \n",
       "25                    NaN                    NaN                    NaN  ...   \n",
       "26                    NaN                    NaN                    NaN  ...   \n",
       "27                    NaN                    NaN                    NaN  ...   \n",
       "28                    NaN                    NaN                    NaN  ...   \n",
       "29                    NaN                    NaN                    NaN  ...   \n",
       "\n",
       "    split2_train_min_both  split3_train_min_both  split4_train_min_both  \\\n",
       "0                     NaN                    NaN                    NaN   \n",
       "1                     NaN                    NaN                    NaN   \n",
       "2                     NaN                    NaN                    NaN   \n",
       "3                     NaN                    NaN                    NaN   \n",
       "4                     NaN                    NaN                    NaN   \n",
       "5                     NaN                    NaN                    NaN   \n",
       "6                     NaN                    NaN                    NaN   \n",
       "7                     NaN                    NaN                    NaN   \n",
       "8                     NaN                    NaN                    NaN   \n",
       "9                     NaN                    NaN                    NaN   \n",
       "10                    NaN                    NaN                    NaN   \n",
       "11                    NaN                    NaN                    NaN   \n",
       "12                    NaN                    NaN                    NaN   \n",
       "13                    NaN                    NaN                    NaN   \n",
       "14                    NaN                    NaN                    NaN   \n",
       "15                    NaN                    NaN                    NaN   \n",
       "16                    NaN                    NaN                    NaN   \n",
       "17                    NaN                    NaN                    NaN   \n",
       "18                    NaN                    NaN                    NaN   \n",
       "19                    NaN                    NaN                    NaN   \n",
       "20                    NaN                    NaN                    NaN   \n",
       "21                    NaN                    NaN                    NaN   \n",
       "22                    NaN                    NaN                    NaN   \n",
       "23                    NaN                    NaN                    NaN   \n",
       "24                    NaN                    NaN                    NaN   \n",
       "25                    NaN                    NaN                    NaN   \n",
       "26                    NaN                    NaN                    NaN   \n",
       "27                    NaN                    NaN                    NaN   \n",
       "28                    NaN                    NaN                    NaN   \n",
       "29                    NaN                    NaN                    NaN   \n",
       "\n",
       "    split5_train_min_both  split6_train_min_both  split7_train_min_both  \\\n",
       "0                     NaN                    NaN                    NaN   \n",
       "1                     NaN                    NaN                    NaN   \n",
       "2                     NaN                    NaN                    NaN   \n",
       "3                     NaN                    NaN                    NaN   \n",
       "4                     NaN                    NaN                    NaN   \n",
       "5                     NaN                    NaN                    NaN   \n",
       "6                     NaN                    NaN                    NaN   \n",
       "7                     NaN                    NaN                    NaN   \n",
       "8                     NaN                    NaN                    NaN   \n",
       "9                     NaN                    NaN                    NaN   \n",
       "10                    NaN                    NaN                    NaN   \n",
       "11                    NaN                    NaN                    NaN   \n",
       "12                    NaN                    NaN                    NaN   \n",
       "13                    NaN                    NaN                    NaN   \n",
       "14                    NaN                    NaN                    NaN   \n",
       "15                    NaN                    NaN                    NaN   \n",
       "16                    NaN                    NaN                    NaN   \n",
       "17                    NaN                    NaN                    NaN   \n",
       "18                    NaN                    NaN                    NaN   \n",
       "19                    NaN                    NaN                    NaN   \n",
       "20                    NaN                    NaN                    NaN   \n",
       "21                    NaN                    NaN                    NaN   \n",
       "22                    NaN                    NaN                    NaN   \n",
       "23                    NaN                    NaN                    NaN   \n",
       "24                    NaN                    NaN                    NaN   \n",
       "25                    NaN                    NaN                    NaN   \n",
       "26                    NaN                    NaN                    NaN   \n",
       "27                    NaN                    NaN                    NaN   \n",
       "28                    NaN                    NaN                    NaN   \n",
       "29                    NaN                    NaN                    NaN   \n",
       "\n",
       "    split8_train_min_both  split9_train_min_both  mean_train_min_both  \\\n",
       "0                     NaN                    NaN                  NaN   \n",
       "1                     NaN                    NaN                  NaN   \n",
       "2                     NaN                    NaN                  NaN   \n",
       "3                     NaN                    NaN                  NaN   \n",
       "4                     NaN                    NaN                  NaN   \n",
       "5                     NaN                    NaN                  NaN   \n",
       "6                     NaN                    NaN                  NaN   \n",
       "7                     NaN                    NaN                  NaN   \n",
       "8                     NaN                    NaN                  NaN   \n",
       "9                     NaN                    NaN                  NaN   \n",
       "10                    NaN                    NaN                  NaN   \n",
       "11                    NaN                    NaN                  NaN   \n",
       "12                    NaN                    NaN                  NaN   \n",
       "13                    NaN                    NaN                  NaN   \n",
       "14                    NaN                    NaN                  NaN   \n",
       "15                    NaN                    NaN                  NaN   \n",
       "16                    NaN                    NaN                  NaN   \n",
       "17                    NaN                    NaN                  NaN   \n",
       "18                    NaN                    NaN                  NaN   \n",
       "19                    NaN                    NaN                  NaN   \n",
       "20                    NaN                    NaN                  NaN   \n",
       "21                    NaN                    NaN                  NaN   \n",
       "22                    NaN                    NaN                  NaN   \n",
       "23                    NaN                    NaN                  NaN   \n",
       "24                    NaN                    NaN                  NaN   \n",
       "25                    NaN                    NaN                  NaN   \n",
       "26                    NaN                    NaN                  NaN   \n",
       "27                    NaN                    NaN                  NaN   \n",
       "28                    NaN                    NaN                  NaN   \n",
       "29                    NaN                    NaN                  NaN   \n",
       "\n",
       "    std_train_min_both  \n",
       "0                  NaN  \n",
       "1                  NaN  \n",
       "2                  NaN  \n",
       "3                  NaN  \n",
       "4                  NaN  \n",
       "5                  NaN  \n",
       "6                  NaN  \n",
       "7                  NaN  \n",
       "8                  NaN  \n",
       "9                  NaN  \n",
       "10                 NaN  \n",
       "11                 NaN  \n",
       "12                 NaN  \n",
       "13                 NaN  \n",
       "14                 NaN  \n",
       "15                 NaN  \n",
       "16                 NaN  \n",
       "17                 NaN  \n",
       "18                 NaN  \n",
       "19                 NaN  \n",
       "20                 NaN  \n",
       "21                 NaN  \n",
       "22                 NaN  \n",
       "23                 NaN  \n",
       "24                 NaN  \n",
       "25                 NaN  \n",
       "26                 NaN  \n",
       "27                 NaN  \n",
       "28                 NaN  \n",
       "29                 NaN  \n",
       "\n",
       "[30 rows x 81 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "90d8cf72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa7350a0610>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "df = pd.DataFrame(grid.cv_results_)\n",
    "for score in ['mean_test_recall', 'mean_test_precision', 'mean_test_min_both']:\n",
    "    plt.plot([_[1] for _ in df['param_class_weight']],\n",
    "            df[score],\n",
    "            label=score)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1c847106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa7009d6fa0>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtEAAAD4CAYAAAAq9brQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAdTklEQVR4nO3dfZRW5Xnv8e81I4hvaBLQgGMyNIdIkBlhHBBDXEBQEbQhJnqqpUrxUJY1niTrHK1olhT9IzGNKyJqY2lqqtSWFaMi9dBGQVxJTQwOgiQoIolEB0ikJBJeJAJe5495nMXLALN55oWX72etWfPse9/33tfmZhY/9tzPfiIzkSRJktR6FZ1dgCRJknS4MURLkiRJBRmiJUmSpIIM0ZIkSVJBhmhJkiSpoGM6u4CD0aNHj6yuru7sMiRJknSEW7x48X9nZs892w/LEF1dXU1DQ0NnlyFJkqQjXET8uqV2l3NIkiRJBRmiJUmSpIIM0ZIkSVJBh+WaaEmSpH3Zvn07jY2NbNu2rbNL0WGkW7duVFVV0aVLl1b1N0RLkqQjSmNjIyeddBLV1dVERGeXo8NAZrJhwwYaGxvp06dPq8a4nEOSJB1Rtm3bxkc+8hEDtFotIvjIRz5S6LcXhmhJknTEMUCrqKJ/ZwzRkiRJUkGGaEmSJKkgQ7QkSdIRaPr06WzduvWgxs6ZM4dXXnmljStqnRNPPBGA1atXM2DAgE6poTUM0ZIk6ag2Z8kaht35LH2m/D+G3fksc5as6eyS2kRHhugdO3Yc1HkOZ4ZoSZJ01JqzZA23PP5z1rzzLgmseeddbnn852UH6dWrV9OvXz8mTZrEgAEDGD9+PPPnz2fYsGH07duXRYsWsWXLFq699loGDx7MoEGDePLJJ5vHnn/++dTV1VFXV8dPfvITAJ577jlGjBjB5ZdfTr9+/Rg/fjyZ2eL5Z8yYwdq1axk5ciQjR44E4Omnn+a8886jrq6OK664gs2bNwMwZcoU+vfvT21tLTfeeCM/+clPmDt3LjfddBMDBw7kl7/8ZYvnGDFiBLfeeivDhw/nnnvuYfHixQwfPpxzzjmH0aNHs27dOgBWrVrFBRdcwNlnn01dXR2//OUv2bx5M6NGjaKuro6amprmaz+sZOZh93XOOeekJElSS1555ZVW9/30Nxbkx29+aq+vT39jQVk1vPHGG1lZWZnLli3LnTt3Zl1dXU6cODHff//9nDNnTo4bNy5vueWWnDVrVmZm/v73v8++ffvm5s2bc8uWLfnuu+9mZubKlSvzg9yzcOHC7N69e7711lu5c+fOHDp0aP74xz/eZw0f//jHc/369ZmZuX79+jz//PNz8+bNmZl555135u23354bNmzIT37yk/n+++8315GZOWHChHz00Uf3e43Dhw/Pv/7rv87MzPfeey/PO++8fPvttzMzc/bs2Tlx4sTMzBwyZEg+/vjjmZn57rvv5pYtW3L79u25cePG5to+8YlPNNdwwgknNP8ZnnXWWa36824rLf3dARqyhTzqh61IkqSj1tp33i3UXkSfPn2oqakB4KyzzmLUqFFEBDU1NaxevZrGxkbmzp3LXXfdBTQ93/rNN9+kd+/e3HDDDSxdupTKykpWrlzZfMwhQ4ZQVVUFwMCBA1m9ejWf+cxnDljLCy+8wCuvvMKwYcMAeO+99zjvvPPo3r073bp1Y9KkSVxyySVceumlha7xz/7szwB47bXX+MUvfsGFF14IwM6dO+nVqxebNm1izZo1XHbZZUDTpwJC06dK3nrrrfzoRz+ioqKCNWvW8Nvf/paPfvSjhc7fmQzRkiTpqNX7lONY00Jg7n3KcWUf+9hjj21+XVFR0bxdUVHBjh07qKys5LHHHuPMM8/cbdy0adM47bTTePnll3n//febg+eex6ysrGz1WuTM5MILL+Tf/u3f9tq3aNEiFixYwOzZs7nvvvt49tlnW32NJ5xwQvPxzzrrLH7605/utv8Pf/hDi+MeeeQR1q9fz+LFi+nSpQvV1dWH3ce0uyZakiQdtW4afSbHdancre24LpXcNPrMfYxoO6NHj+bee+9tXte8ZMkSADZu3EivXr2oqKhg1qxZ7Ny586COf9JJJ7Fp0yYAhg4dyvPPP8+qVasA2Lp1KytXrmTz5s1s3LiRsWPHMn36dJYuXbrX2NY488wzWb9+fXOI3r59O8uXL6d79+5UVVUxZ84cAP74xz+ydetWNm7cyKmnnkqXLl1YuHAhv/71rw/qGjuTIVqSJB21Pj/odL7xhRpOP+U4Ajj9lOP4xhdq+Pyg09v93Lfddhvbt2+ntraWAQMGcNtttwFw/fXX89BDDzF06FBWrlzZfLe3qMmTJzNmzBhGjhxJz549+ed//meuuuoqamtrGTp0KCtWrGDTpk1ceuml1NbWMnz4cO6++24ArrzySr71rW8xaNCgfb6xcFddu3blBz/4ATfffDNnn302AwcObH5D5KxZs5gxYwa1tbV8+tOf5je/+Q3jx4+noaGB+vp6HnnkEfr163dQ19iZ4oP//RxO6uvrs6GhobPLkCRJh6BXX32VT33qU51dhg5DLf3diYjFmVm/Z1/vREuSJEkF+cZCSZKkw9hll13GG2+8sVvbN7/5TUaPHt0mx//Sl77E888/v1vbV77yFSZOnNgmxz9cGaIlSZIOY0888US7Hv/+++9v1+MfrlzOIUmSJBVkiJYkSZIKMkRLkiRJBRmiJUmSpILaJERHxMUR8VpErIqIKS3sj4iYUdq/LCLq9thfGRFLIuKptqhHkiTpaDd9+nS2bt1aeNzUqVOZP39+O1R0cA5UzwMPPMDDDz/cgRU1KfvDViKiElgJXAg0Ai8CV2XmK7v0GQv8b2AscC5wT2aeu8v+/wPUA90z89IDndMPW5EkSftS+MNWln0fFtwBGxvh5CoYNRVq/2f7FdhBqquraWhooEePHnvt27lzJ5WVlS2Mal+ddd7W6ugPWxkCrMrMX2Xme8BsYNwefcYBD2eTF4BTIqJXqbAq4BLgu21QiyRJUust+z78+5dh41tANn3/9y83tZdh9erV9OvXj0mTJjFgwADGjx/P/PnzGTZsGH379mXRokVs2bKFa6+9lsGDBzNo0CCefPLJ5rHnn38+dXV11NXVNX989nPPPceIESO4/PLL6devH+PHj2dfN0NnzJjB2rVrGTlyJCNHjgTgxBNPZOrUqZx77rn89Kc/5Y477mDw4MEMGDCAyZMnNx/rL//yL/nBD34ANAXxv/3bv6Wuro6amhpWrFixz2ueNm0aV199NZ/97Gfp27cv//iP/9hc98iRI/nzP/9zampq2LlzJzfddBODBw+mtraWf/iHf2g+xt/93d9RU1PD2WefzZQpU/aqZ8qUKfTv35/a2lpuvPHG5vPeddddACxdupShQ4dSW1vLZZddxu9//3sARowYwc0338yQIUP45Cc/yY9//OOiU7qXtnhO9OnAW7tsN9J0t/lAfU4H1gHTgb8BTtrfSSJiMjAZ4GMf+1hZBUuSJAFNd6C3v7t72/Z3m9rLvBu9atUqHn30UWbOnMngwYP513/9V/7rv/6LuXPn8vWvf53+/fvz2c9+lgcffJB33nmHIUOGcMEFF3DqqafyzDPP0K1bN15//XWuuuoqPvgN/JIlS1i+fDm9e/dm2LBhPP/883zmM5/Z69xf/vKX+fa3v83ChQub70Rv2bKFAQMGcMcddwDQv39/pk6dCsDVV1/NU089xZ/+6Z/udawePXrw0ksv8fd///fcddddfPe7+77vuWzZMl544QW2bNnCoEGDuOSSSwBYtGgRv/jFL+jTpw8zZ87k5JNP5sUXX+SPf/wjw4YN46KLLmLFihXMmTOHn/3sZxx//PH87ne/2+3Yv/vd73jiiSdYsWIFEcE777yz1/mvueYa7r33XoYPH87UqVO5/fbbmT59OgA7duxg0aJFzJs3j9tvv73sJSttcSc6Wmjb879FLfaJiEuBtzNz8YFOkpkzM7M+M+t79ux5MHVKkiTtbmNjsfYC+vTpQ01NDRUVFZx11lmMGjWKiKCmpobVq1fz9NNPc+eddzJw4EBGjBjBtm3bePPNN9m+fTt/9Vd/RU1NDVdccQWvvNK8QpYhQ4ZQVVVFRUUFAwcOZPXq1a2up7Kyki9+8YvN2wsXLuTcc8+lpqaGZ599luXLl7c47gtf+AIA55xzzgHPN27cOI477jh69OjByJEjWbRoUXPdffr0AeDpp5/m4YcfZuDAgZx77rls2LCB119/nfnz5zNx4kSOP/54AD784Q/vduzu3bvTrVs3Jk2axOOPP97c7wMbN27knXfeYfjw4QBMmDCBH/3oRwd1Ha3RFneiG4EzdtmuAta2ss/lwOdKa6a7Ad0j4l8y8y/aoC5JkqT9O7mqtJSjhfYyHXvssc2vKyoqmrcrKirYsWMHlZWVPPbYY5x55pm7jZs2bRqnnXYaL7/8Mu+//z7dunVr8ZiVlZXs2LGj1fV069ateT3ytm3buP7662loaOCMM85g2rRpbNu2bb/X0ZrzRUSL2yeccEJzW2Zy77337vWx5P/5n/+51/hdHXPMMSxatIgFCxYwe/Zs7rvvPp599tn91nOw19EabXEn+kWgb0T0iYiuwJXA3D36zAWuKT2lYyiwMTPXZeYtmVmVmdWlcc8aoCVJUocZNRW6HLd7W5fjmtrb2ejRo7n33nub1yIvWbIEaLqj2qtXLyoqKpg1axY7d+48qOOfdNJJbNq0qcV9HwTmHj16sHnz5uY1x+V68skn2bZtGxs2bOC5555j8ODBe/UZPXo03/nOd9i+fTsAK1euZMuWLVx00UU8+OCDzU8U2XM5x+bNm9m4cSNjx45l+vTpLF26dLf9J598Mh/60Iea1zvPmjWr+a50eyj7TnRm7oiIG4AfApXAg5m5PCKuK+1/AJhH05M5VgFbgYnlnleSJKlsH6x77oSnc9x222189atfpba2lsykurqap556iuuvv54vfvGLPProo4wcOXK3u7hFTJ48mTFjxtCrVy8WLly4275TTjmleclIdXV1i2H3YAwZMoRLLrmEN998k9tuu43evXuzcuXK3fpMmjSJ1atXU1dXR2bSs2dP5syZw8UXX8zSpUupr6+na9eujB07lq9//evN4zZt2sS4cePYtm0bmcndd9+91/kfeughrrvuOrZu3cqf/Mmf8L3vfa9NrqslZT/irjP4iDtJkrQvhR9xpzYxbdo0TjzxxOanZhyOOvoRd5IkSdJRpS3eWChJkqROctlll/HGG2/s1vbNb35zrzfutZXvfe973HPPPbu1DRs2jPvvv79dzneoMkRLkqQjTmbu90kPR5InnniiQ883ceJEJk488t7eVnSJs8s5JEnSEaVbt25s2LChcCjS0Ssz2bBhw26PEzwQ70RLkqQjSlVVFY2Njaxfv76zS9FhpFu3blRVtf754IZoSZJ0ROnSpUvzp+NJ7cXlHJIkSVJBhmhJkiSpIEO0JEmSVJAhWpIkSSrIEC1JkiQVZIiWJEmSCjJES5IkSQUZoiVJkqSCDNGSJElSQYZoSZIkqSBDtCRJklSQIVqSJEkqyBAtSZIkFWSIliRJkgoyREuSJEkFGaIlSZKkggzRkiRJUkGGaEmSJKkgQ7QkSZJUkCFakiRJKsgQLUmSJBVkiJYkSZIKMkRLkiRJBRmiJUmSpILaJERHxMUR8VpErIqIKS3sj4iYUdq/LCLqSu1nRMTCiHg1IpZHxFfaoh5JkiSpPZUdoiOiErgfGAP0B66KiP57dBsD9C19TQa+U2rfAfzfzPwUMBT4UgtjJUmSpENKW9yJHgKsysxfZeZ7wGxg3B59xgEPZ5MXgFMioldmrsvMlwAycxPwKnB6G9QkSZIktZu2CNGnA2/tst3I3kH4gH0iohoYBPysDWqSJEmS2k1bhOhooS2L9ImIE4HHgK9m5h9aPEnE5IhoiIiG9evXH3SxkiRJUrnaIkQ3Amfssl0FrG1tn4joQlOAfiQzH9/XSTJzZmbWZ2Z9z54926BsSZIk6eC0RYh+EegbEX0ioitwJTB3jz5zgWtKT+kYCmzMzHUREcA/Aa9m5rfboBZJkiSp3R1T7gEyc0dE3AD8EKgEHszM5RFxXWn/A8A8YCywCtgKTCwNHwZcDfw8IpaW2m7NzHnl1iVJkiS1l8jcc/nyoa++vj4bGho6uwxJkiQd4SJicWbW79nuJxZKkiRJBRmiJUmSpIIM0ZIkSVJBhmhJkiSpIEO0JEmSVJAhWpIkSSrIEC1JkiQVZIiWJEmSCjJES5IkSQUZoiVJkqSCDNGSJElSQYZoSZIkqSBDtCRJklSQIVqSJEkqyBAtSZIkFWSIliRJkgoyREuSJEkFGaIlSZKkggzRkiRJUkGGaEmSJKkgQ7QkSZJUkCFakiRJKsgQLUmSJBVkiJYkSZIKMkRLkiRJBRmiJUmSpIIM0ZIkSVJBhmhJkiSpIEO0JEmSVJAhWpIkSSrIEC1JkiQV1CYhOiIujojXImJVRExpYX9ExIzS/mURUdfasZIkSdKhpuwQHRGVwP3AGKA/cFVE9N+j2xigb+lrMvCdAmMlSZKkQ0pb3IkeAqzKzF9l5nvAbGDcHn3GAQ9nkxeAUyKiVyvHSpIkSYeUtgjRpwNv7bLdWGprTZ/WjAUgIiZHRENENKxfv77soiVJkqSD1RYhOlpoy1b2ac3YpsbMmZlZn5n1PXv2LFiiJEmS1HaOaYNjNAJn7LJdBaxtZZ+urRgrSZIkHVLa4k70i0DfiOgTEV2BK4G5e/SZC1xTekrHUGBjZq5r5VhJkiTpkFL2nejM3BERNwA/BCqBBzNzeURcV9r/ADAPGAusArYCE/c3ttyaJEmSpPYUmS0uQT6k1dfXZ0NDQ2eXIUmSpCNcRCzOzPo92/3EQkmSJKkgQ7QkSZJUkCFakiRJKsgQLUmSJBVkiJYkSZIKMkRLkiRJBRmiJUmSpIIM0ZIkSVJBhmhJkiSpIEO0JEmSVJAhWpIkSSrIEC1JkiQVZIiWJEmSCjJES5IkSQUZoiVJkqSCDNGSJElSQYZoSZIkqSBDtCRJklSQIVqSJEkqyBAtSZIkFWSIliRJkgoyREuSJEkFGaIlSZKkggzRkiRJUkGGaEmSJKkgQ7QkSZJUkCFakiRJKsgQLUmSJBVkiJYkSZIKMkRLkiRJBZUVoiPiwxHxTES8Xvr+oX30uzgiXouIVRExZZf2b0XEiohYFhFPRMQp5dQjSZIkdYRy70RPARZkZl9gQWl7NxFRCdwPjAH6A1dFRP/S7meAAZlZC6wEbimzHkmSJKndlRuixwEPlV4/BHy+hT5DgFWZ+avMfA+YXRpHZj6dmTtK/V4AqsqsR5IkSWp35Ybo0zJzHUDp+6kt9DkdeGuX7cZS256uBf6jzHokSZKkdnfMgTpExHzgoy3s+lorzxEttOUe5/gasAN4ZD91TAYmA3zsYx9r5aklSZKktnfAEJ2ZF+xrX0T8NiJ6Zea6iOgFvN1Ct0bgjF22q4C1uxxjAnApMCozk33IzJnATID6+vp99pMkSZLaW7nLOeYCE0qvJwBPttDnRaBvRPSJiK7AlaVxRMTFwM3A5zJza5m1SJIkSR2i3BB9J3BhRLwOXFjaJiJ6R8Q8gNIbB28Afgi8Cnw/M5eXxt8HnAQ8ExFLI+KBMuuRJEmS2t0Bl3PsT2ZuAEa10L4WGLvL9jxgXgv9/kc555ckSZI6g59YKEmSJBVkiJYkSZIKMkRLkiRJBRmiJUmSpIIM0ZIkSVJBhmhJkiSpIEO0JEmSVJAhWpIkSSrIEC1JkiQVZIiWJEmSCjJES5IkSQUZoiVJkqSCDNGSJElSQYZoSZIkqSBDtCRJklSQIVqSJEkqyBAtSZIkFWSIliRJkgoyREuSJEkFGaIlSZKkggzRkiRJUkGGaEmSJKkgQ7QkSZJUkCFakiRJKsgQLUmSJBVkiJYkSZIKMkRLkiRJBRmiJUmSpIIM0ZIkSVJBhmhJkiSpIEO0JEmSVFBZIToiPhwRz0TE66XvH9pHv4sj4rWIWBURU1rYf2NEZET0KKceSZIkqSOUeyd6CrAgM/sCC0rbu4mISuB+YAzQH7gqIvrvsv8M4ELgzTJrkSRJkjpEuSF6HPBQ6fVDwOdb6DMEWJWZv8rM94DZpXEfuBv4GyDLrEWSJEnqEOWG6NMycx1A6fupLfQ5HXhrl+3GUhsR8TlgTWa+fKATRcTkiGiIiIb169eXWbYkSZJ08I45UIeImA98tIVdX2vlOaKFtoyI40vHuKg1B8nMmcBMgPr6eu9aS5IkqdMcMERn5gX72hcRv42IXpm5LiJ6AW+30K0ROGOX7SpgLfAJoA/wckR80P5SRAzJzN8UuAZJkiSpQ5W7nGMuMKH0egLwZAt9XgT6RkSfiOgKXAnMzcyfZ+apmVmdmdU0he06A7QkSZIOdeWG6DuBCyPidZqesHEnQET0joh5AJm5A7gB+CHwKvD9zFxe5nklSZKkTnPA5Rz7k5kbgFEttK8Fxu6yPQ+Yd4BjVZdTiyRJktRR/MRCSZIkqSBDtCRJklSQIVqSJEkqyBAtSZIkFWSIliRJkgoyREuSJEkFGaIlSZKkggzRkiRJUkGGaEmSJKkgQ7QkSZJUkCFakiRJKsgQLUmSJBVkiJYkSZIKMkRLkiRJBRmiJUmSpIIM0ZIkSVJBhmhJkiSpIEO0JEmSVJAhWpIkSSrIEC1JkiQVZIiWJEmSCjJES5IkSQUZoiVJkqSCDNGSJElSQZGZnV1DYRGxHvh1Z9dxlOgB/HdnF6F25zwfHZznI59zfHRwnjvWxzOz556Nh2WIVseJiIbMrO/sOtS+nOejg/N85HOOjw7O86HB5RySJElSQYZoSZIkqSBDtA5kZmcXoA7hPB8dnOcjn3N8dHCeDwGuiZYkSZIK8k60JEmSVJAhWpIkSSrIEC0i4sMR8UxEvF76/qF99Ls4Il6LiFURMaWF/TdGREZEj/avWkWVO88R8a2IWBERyyLiiYg4pcOK13614mczImJGaf+yiKhr7VgdOg52niPijIhYGBGvRsTyiPhKx1ev1irn57m0vzIilkTEUx1X9dHJEC2AKcCCzOwLLCht7yYiKoH7gTFAf+CqiOi/y/4zgAuBNzukYh2Mcuf5GWBAZtYCK4FbOqRq7deBfjZLxgB9S1+Tge8UGKtDQDnzDOwA/m9mfgoYCnzJeT40lTnPH/gK8Go7lyoM0WoyDnio9Poh4PMt9BkCrMrMX2Xme8Ds0rgP3A38DeA7VQ9dZc1zZj6dmTtK/V4Aqtq3XLXSgX42KW0/nE1eAE6JiF6tHKtDw0HPc2auy8yXADJzE00B6/SOLF6tVs7PMxFRBVwCfLcjiz5aGaIFcFpmrgMofT+1hT6nA2/tst1YaiMiPgesycyX27tQlaWsed7DtcB/tHmFOhitmbN99WntfKvzlTPPzSKiGhgE/KztS1QbKHeep9N0Q+v9dqpPuzimswtQx4iI+cBHW9j1tdYeooW2jIjjS8e46GBrU9tpr3ne4xxfo+nXw48Uq07t5IBztp8+rRmrQ0M589y0M+JE4DHgq5n5hzasTW3noOc5Ii4F3s7MxRExoq0L094M0UeJzLxgX/si4rcf/Mqv9Cuht1vo1gicsct2FbAW+ATQB3g5Ij5ofykihmTmb9rsAtQq7TjPHxxjAnApMCp9yPyhYr9zdoA+XVsxVoeGcuaZiOhCU4B+JDMfb8c6VZ5y5vly4HMRMRboBnSPiH/JzL9ox3qPai7nEMBcYELp9QTgyRb6vAj0jYg+EdEVuBKYm5k/z8xTM7M6M6tp+uGuM0Afkg56nqHpHePAzcDnMnNrB9Sr1tnnnO1iLnBN6V39Q4GNpSU9rRmrQ8NBz3M03eH4J+DVzPx2x5atgg56njPzlsysKv1bfCXwrAG6fXknWgB3At+PiP9F09M1rgCIiN7AdzNzbGbuiIgbgB8ClcCDmbm80yrWwSh3nu8DjgWeKf3W4YXMvK6jL0K729ecRcR1pf0PAPOAscAqYCswcX9jO+EydADlzDMwDLga+HlELC213ZqZ8zrwEtQKZc6zOpgf+y1JkiQV5HIOSZIkqSBDtCRJklSQIVqSJEkqyBAtSZIkFWSIliRJkgoyREuSJEkFGaIlSZKkgv4/RR2SX+IzoT0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "df = pd.DataFrame(grid.cv_results_)\n",
    "for score in ['mean_test_recall', 'mean_train_precision']:\n",
    "    plt.scatter(x=[_[1] for _ in df['param_class_weight']],\n",
    "               y = df[score.replace('test', 'train')],\n",
    "               label=score)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "815fc00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = make_scorer(min_recall_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae282235",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38836fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
